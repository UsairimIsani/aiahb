{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:11.147184Z","iopub.status.busy":"2023-02-05T10:48:11.146873Z","iopub.status.idle":"2023-02-05T10:48:15.044226Z","shell.execute_reply":"2023-02-05T10:48:15.043106Z","shell.execute_reply.started":"2023-02-05T10:48:11.147151Z"},"trusted":true},"outputs":[],"source":["import glob\n","import cv2\n","import os\n","\n","import numpy as np \n","import pandas as pd \n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score, roc_auc_score, cohen_kappa_score, precision_score, recall_score, accuracy_score, confusion_matrix\n","from tensorflow.keras.utils import to_categorical\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(os.listdir(\"../input/intel-mobileodt-cervical-cancer-screening\"))"]},{"cell_type":"markdown","metadata":{},"source":["# Data import"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.048469Z","iopub.status.busy":"2023-02-05T10:48:15.047603Z","iopub.status.idle":"2023-02-05T10:48:15.081158Z","shell.execute_reply":"2023-02-05T10:48:15.080155Z","shell.execute_reply.started":"2023-02-05T10:48:15.048437Z"},"trusted":true},"outputs":[],"source":["#getting the total number of images in the training set\n","\n","base_dir = '../input/intel-mobileodt-cervical-cancer-screening'\n","\n","train_dir = os.path.join(base_dir,'train', 'train')\n","\n","type1_dir = os.path.join(base_dir,'Type_1')\n","type2_dir = os.path.join(base_dir,'Type_2')\n","type3_dir = os.path.join(base_dir,'Type_3')\n","\n","type1_files = glob.glob(type1_dir+'/*.jpg')\n","type2_files = glob.glob(type2_dir+'/*.jpg')\n","type3_files = glob.glob(type3_dir+'/*.jpg')\n","\n","added_type1_files  =  glob.glob(os.path.join(base_dir, \"additional_Type_1_v2\", \"Type_1\")+'/*.jpg')\n","added_type2_files  =  glob.glob(os.path.join(base_dir, \"additional_Type_2_v2\", \"Type_2\")+'/*.jpg')\n","added_type3_files  =  glob.glob(os.path.join(base_dir, \"additional_Type_3_v2\", \"Type_3\")+'/*.jpg')\n","\n","type1_files = type1_files + added_type1_files\n","type2_files = type2_files + added_type2_files\n","type3_files = type3_files + added_type3_files\n","\n","\n","print('Number of images in a train set of type 1: ', len(type1_files))\n","print('Number of images in a train set of type 2: ', len(type2_files))\n","print('Number of images in a train set of type 3: ', len(type3_files))\n","print('Total number of images in a train set: ', sum([len(type1_files), len(type2_files), len(type3_files)]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.084525Z","iopub.status.busy":"2023-02-05T10:48:15.084193Z","iopub.status.idle":"2023-02-05T10:48:15.106838Z","shell.execute_reply":"2023-02-05T10:48:15.105657Z","shell.execute_reply.started":"2023-02-05T10:48:15.084496Z"},"trusted":true},"outputs":[],"source":["# Building a dataframe mapping images and Cancer type\n","\n","files_df = pd.DataFrame({\n","    'filename': type1_files + type2_files + type3_files,\n","    'label': ['Type_1'] * len(type1_files) + ['Type_2'] * len(type2_files) + ['Type_3'] * len(type3_files)\n","})\n","\n","files_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.109191Z","iopub.status.busy":"2023-02-05T10:48:15.108775Z","iopub.status.idle":"2023-02-05T10:48:15.12476Z","shell.execute_reply":"2023-02-05T10:48:15.123655Z","shell.execute_reply.started":"2023-02-05T10:48:15.109152Z"},"trusted":true},"outputs":[],"source":["#Shuffle data\n","\n","random_state = 42\n","\n","files_df = files_df.sample(frac=1, random_state=random_state)\n","# files_df = files_df.sample(n=100, random_state=random_state)\n","\n","files_df"]},{"cell_type":"markdown","metadata":{},"source":["# Data exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.127006Z","iopub.status.busy":"2023-02-05T10:48:15.126617Z","iopub.status.idle":"2023-02-05T10:48:15.148228Z","shell.execute_reply":"2023-02-05T10:48:15.147256Z","shell.execute_reply.started":"2023-02-05T10:48:15.126959Z"},"trusted":true},"outputs":[],"source":["files_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.150277Z","iopub.status.busy":"2023-02-05T10:48:15.149903Z","iopub.status.idle":"2023-02-05T10:48:15.161316Z","shell.execute_reply":"2023-02-05T10:48:15.160256Z","shell.execute_reply.started":"2023-02-05T10:48:15.150239Z"},"trusted":true},"outputs":[],"source":["#Check for duplicates\n","len(files_df[files_df.duplicated()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.163696Z","iopub.status.busy":"2023-02-05T10:48:15.163037Z","iopub.status.idle":"2023-02-05T10:48:15.177097Z","shell.execute_reply":"2023-02-05T10:48:15.176201Z","shell.execute_reply.started":"2023-02-05T10:48:15.16366Z"},"trusted":true},"outputs":[],"source":["#Get count of each type \n","type_count = pd.DataFrame(files_df['label'].value_counts())\n","type_count"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(list(type_count.columns)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.178754Z","iopub.status.busy":"2023-02-05T10:48:15.178458Z","iopub.status.idle":"2023-02-05T10:48:15.397561Z","shell.execute_reply":"2023-02-05T10:48:15.396533Z","shell.execute_reply.started":"2023-02-05T10:48:15.178722Z"},"trusted":true},"outputs":[],"source":["# Display barplot of type count\n","\n","plt.figure(figsize = (15, 6))\n","sns.barplot(x= type_count[list(type_count.columns)[0]], y= type_count.index.to_list())\n","plt.title('Cervical Cancer Type Distribution')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:15.399575Z","iopub.status.busy":"2023-02-05T10:48:15.399218Z","iopub.status.idle":"2023-02-05T10:48:19.691573Z","shell.execute_reply":"2023-02-05T10:48:19.690522Z","shell.execute_reply.started":"2023-02-05T10:48:15.399537Z"},"trusted":true},"outputs":[],"source":["# Display sample images of types\n","for label in ('Type_1', 'Type_2', 'Type_3'):\n","    filepaths = files_df[files_df['label']==label]['filename'].values[:5]\n","    fig = plt.figure(figsize= (15, 6))\n","    for i, path in enumerate(filepaths):\n","        img = cv2.imread(path)\n","        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","        img = cv2.resize(img, (224, 224))\n","        fig.add_subplot(1, 5, i+1)\n","        plt.imshow(img)\n","        plt.subplots_adjust(hspace=0.5)\n","        plt.axis(False)\n","        plt.title(label)"]},{"cell_type":"markdown","metadata":{},"source":["# Data propocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:19.694704Z","iopub.status.busy":"2023-02-05T10:48:19.694038Z","iopub.status.idle":"2023-02-05T10:48:19.707815Z","shell.execute_reply":"2023-02-05T10:48:19.706835Z","shell.execute_reply.started":"2023-02-05T10:48:19.694665Z"},"trusted":true},"outputs":[],"source":["# Split training,val and test set : 70:15:15\n","\n","train_files, test_files, train_labels, test_labels = train_test_split(files_df['filename'].values,\n","                                                                      files_df['label'].values, \n","                                                                      test_size=0.3, \n","                                                                      random_state=random_state)\n","\n","test_files, val_files, test_labels, val_labels = train_test_split(test_files,\n","                                                                  test_labels, \n","                                                                  test_size=0.5, \n","                                                                  random_state=random_state)\n","\n","\n","print('Number of images in train set: ', train_files.shape)\n","print('Number of images in validation set: ', val_files.shape)\n","print('Number of images in test set: ', test_files.shape, '\\n')\n","\n","print('Train:', Counter(train_labels), '\\nVal:', Counter(val_labels), '\\nTest:', Counter(test_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:19.710057Z","iopub.status.busy":"2023-02-05T10:48:19.70966Z","iopub.status.idle":"2023-02-05T10:48:19.71781Z","shell.execute_reply":"2023-02-05T10:48:19.71652Z","shell.execute_reply.started":"2023-02-05T10:48:19.710021Z"},"trusted":true},"outputs":[],"source":["def load_images(files, labels):\n","    features = []\n","    correct_labels = []\n","    bad_images = 0\n","    \n","    for i in range(len(files)):\n","        try:\n","            img = cv2.imread(files[i])\n","            resized_img = cv2.resize(img, (160, 160))\n","            \n","            features.append(np.array(resized_img))\n","            correct_labels.append(labels[i])\n","                   \n","        except Exception as e:\n","            bad_images+=1\n","            print('Encoutered bad image')\n","    print('Bad images ecountered:', bad_images)\n","    return np.array(features), np.array(correct_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T10:48:19.723951Z","iopub.status.busy":"2023-02-05T10:48:19.723609Z","iopub.status.idle":"2023-02-05T11:11:50.219834Z","shell.execute_reply":"2023-02-05T11:11:50.218665Z","shell.execute_reply.started":"2023-02-05T10:48:19.723921Z"},"trusted":true},"outputs":[],"source":["# Load training and evaluation data\n","train_features, train_labels = load_images(train_files, train_labels)\n","print('Train images loaded')\n","\n","val_features, val_labels = load_images(val_files, val_labels)\n","print('Validation images loaded')\n","\n","test_features, test_labels = load_images(test_files, test_labels)\n","print('test images loaded')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:11:50.221761Z","iopub.status.busy":"2023-02-05T11:11:50.221431Z","iopub.status.idle":"2023-02-05T11:11:50.233657Z","shell.execute_reply":"2023-02-05T11:11:50.232637Z","shell.execute_reply.started":"2023-02-05T11:11:50.221732Z"},"trusted":true},"outputs":[],"source":["# check lengths of training and evaluation  sets\n","len(train_features), len(train_labels), len(val_features), len(val_labels), len(test_features), len(test_labels) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:11:50.236036Z","iopub.status.busy":"2023-02-05T11:11:50.2354Z","iopub.status.idle":"2023-02-05T11:11:50.242068Z","shell.execute_reply":"2023-02-05T11:11:50.24105Z","shell.execute_reply.started":"2023-02-05T11:11:50.235997Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","NUM_CLASSES = 3\n","EPOCHS = 10\n","INPUT_SHAPE = (160, 160, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:11:50.244177Z","iopub.status.busy":"2023-02-05T11:11:50.243549Z","iopub.status.idle":"2023-02-05T11:11:50.503258Z","shell.execute_reply":"2023-02-05T11:11:50.501925Z","shell.execute_reply.started":"2023-02-05T11:11:50.24414Z"},"trusted":true},"outputs":[],"source":["# encode train+val sets text categories with labels\n","le = LabelEncoder()\n","le.fit(train_labels)\n","\n","train_labels_enc = le.transform(train_labels)\n","val_labels_enc = le.transform(val_labels)\n","\n","train_labels_1hotenc = tf.keras.utils.to_categorical(train_labels_enc, num_classes=NUM_CLASSES)\n","val_labels_1hotenc = tf.keras.utils.to_categorical(val_labels_enc, num_classes=NUM_CLASSES)\n","\n","print(train_labels[:6], train_labels_enc[:6])\n","print(train_labels[:6], train_labels_1hotenc[:6])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:11:50.507885Z","iopub.status.busy":"2023-02-05T11:11:50.507493Z","iopub.status.idle":"2023-02-05T11:11:50.520206Z","shell.execute_reply":"2023-02-05T11:11:50.519067Z","shell.execute_reply.started":"2023-02-05T11:11:50.507849Z"},"trusted":true},"outputs":[],"source":["\n","le = LabelEncoder()\n","le.fit(test_labels)\n","\n","test_labels_enc = le.transform(test_labels)\n","\n","test_labels_1hotenc = tf.keras.utils.to_categorical(test_labels_enc, num_classes=NUM_CLASSES)\n","\n","\n","print(test_labels[:6], test_labels_enc[:6])\n","print(test_labels[:6], test_labels_1hotenc[:6])"]},{"cell_type":"markdown","metadata":{},"source":["# Data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:11:50.523636Z","iopub.status.busy":"2023-02-05T11:11:50.523103Z","iopub.status.idle":"2023-02-05T11:11:52.199532Z","shell.execute_reply":"2023-02-05T11:11:52.197513Z","shell.execute_reply.started":"2023-02-05T11:11:50.523572Z"},"trusted":true},"outputs":[],"source":["data_augmentation = tf.keras.Sequential([\n","  tf.keras.layers.RandomFlip('horizontal'),\n","  tf.keras.layers.RandomRotation(0.2),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:11:52.203458Z","iopub.status.busy":"2023-02-05T11:11:52.203144Z","iopub.status.idle":"2023-02-05T11:11:52.994942Z","shell.execute_reply":"2023-02-05T11:11:52.993683Z","shell.execute_reply.started":"2023-02-05T11:11:52.203428Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10, 10))\n","first_image = train_features[0]\n","for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n","    plt.imshow(augmented_image[0] / 255)\n","    plt.axis('off')\n","        "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_accuracy_metrics(model, train_features=train_features, train_labels=train_labels_enc, test_features=test_features, test_labels=test_labels_enc, val_features=val_features, val_labels=val_labels_enc):    \n","    train_predicted = np.argmax(model.predict(train_features),axis=1)\n","    test_predicted = np.argmax(model.predict(test_features),axis=1)\n","    val_predicted = np.argmax(model.predict(val_features),axis=1)\n","\n","    print(\"Train accuracy Score------------>\")\n","    print (\"{0:.3f}\".format(accuracy_score(train_labels, train_predicted) *100), \"%\")\n","    \n","    print(\"Val accuracy Score--------->\")\n","    print(\"{0:.3f}\".format(accuracy_score(val_labels, val_predicted)*100), \"%\")\n","    \n","    print(\"Test accuracy Score--------->\")\n","    print(\"{0:.3f}\".format(accuracy_score(test_labels, test_predicted)*100), \"%\")\n","    \n","    print(\"F1 Score--------------->\")\n","    print(\"{0:.3f}\".format(f1_score(test_labels, test_predicted, average = 'weighted')*100), \"%\")\n","    \n","    print(\"Cohen Kappa Score------------->\")\n","    print(\"{0:.3f}\".format(cohen_kappa_score(test_labels, test_predicted)*100), \"%\")\n","    \n","    \n","    print(\"ROC AUC Score------------->\")\n","    print(\"{0:.3f}\".format(roc_auc_score(to_categorical(test_labels, num_classes = 3), test_predicted.reshape(-1, 1), multi_class='ovr')*100), \"%\")\n","    \n","    print(\"Recall-------------->\")\n","    print(\"{0:.3f}\".format(recall_score(test_labels, test_predicted, average = 'weighted')*100), \"%\")\n","    \n","    print(\"Precision-------------->\")\n","    print(\"{0:.3f}\".format(precision_score(test_labels, test_predicted, average = 'weighted')*100), \"%\")\n","    \n","    cf_matrix_test = confusion_matrix(test_labels, test_predicted)\n","    cf_matrix_val = confusion_matrix(val_labels, val_predicted)\n","    \n","    plt.figure(figsize = (12, 6))\n","    plt.subplot(121)\n","    sns.heatmap(cf_matrix_val, annot=True, cmap='Blues')\n","    plt.title(\"Val Confusion matrix\")\n","    \n","    plt.subplot(122)\n","    sns.heatmap(cf_matrix_test, annot=True, cmap='Blues')\n","    plt.title(\"Test Confusion matrix\")\n","    \n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# General Model Fit"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T11:13:10.305578Z","iopub.status.busy":"2023-02-05T11:13:10.305201Z","iopub.status.idle":"2023-02-05T11:13:10.316018Z","shell.execute_reply":"2023-02-05T11:13:10.314139Z","shell.execute_reply.started":"2023-02-05T11:13:10.30554Z"},"trusted":true},"outputs":[],"source":["def learning_performance_chart(title, history):\n","    #plots a chart showing the change in accuracy and loss function over epochs\n","    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","    t = f.suptitle(title, fontsize=12)\n","    f.subplots_adjust(top=0.85, wspace=0.3)\n","\n","    max_epoch = len(history.history['accuracy'])+1\n","    epoch_list = list(range(1,max_epoch))\n","    ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n","    ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n","    ax1.set_xticks(np.arange(1, max_epoch, 5))\n","    ax1.set_ylabel('Accuracy Value')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_title('Accuracy')\n","    l1 = ax1.legend(loc=\"best\")\n","\n","    ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n","    ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n","    ax2.set_xticks(np.arange(1, max_epoch, 5))\n","    ax2.set_ylabel('Loss Value')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_title('Loss')\n","    l2 = ax2.legend(loc=\"best\")\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fit_model(model_name, base_model, train_features, train_labels, validate_it,training = False, epochs = EPOCHS, batch_size= BATCH_SIZE):\n","    \n","    inputs = tf.keras.Input(shape=INPUT_SHAPE)\n","    \n","    x = data_augmentation(inputs)\n","    x = base_model(x, training=training)\n","    \n","    if not model_name.startswith('CNN'):\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    \n","    x = tf.keras.layers.Dropout(0.2)(x)\n","    \n","    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n","    \n","    model = tf.keras.Model(inputs, outputs)\n","    \n","    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","    \n","    model.compile(loss='categorical_crossentropy', optimizer ='adam', metrics=['accuracy'])\n","    \n","    print(\"Model Summary.\")\n","    \n","    print(model.summary())\n","    \n","    history = model.fit(x=train_features,y=train_labels ,validation_data=validate_it, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[es])\n","\n","    learning_performance_chart(title=\"{} learning performance.\".format(model_name), history=history)\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# MobileNet Pretranined"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_model = tf.keras.applications.MobileNet(include_top=False, \n","                                               weights='imagenet', \n","                                               input_shape=INPUT_SHAPE)\n","\n","base_model.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mobilenet = fit_model(\"MobileNet\", base_model, train_features, train_labels_1hotenc, (val_features, val_labels_1hotenc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('MobileNet performance on the test set:')\n","get_accuracy_metrics(mobilenet)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
